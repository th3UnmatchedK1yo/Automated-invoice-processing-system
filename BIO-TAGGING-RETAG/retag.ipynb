{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cbdbb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ tokenised: 01GTKT0_0003263.json\n",
      "✓ tokenised: 01GTKT0_0003273.json\n",
      "✓ tokenised: 01GTKT0_0003722.json\n",
      "✓ tokenised: 1C22THS_00000212.json\n",
      "✓ tokenised: 1C22THS_00000402.json\n",
      "✓ tokenised: 1C22THS_00000432.json\n",
      "✓ tokenised: 1C22THS_00000677.json\n",
      "✓ tokenised: 1C22THS_00000905.json\n",
      "✓ tokenised: 1C22THS_00001048.json\n",
      "✓ tokenised: 1C22THS_00001068.json\n",
      "✓ tokenised: 1C22THS_00001070.json\n",
      "✓ tokenised: 1C22THS_00001080.json\n",
      "✓ tokenised: 1C22THS_00001123.json\n",
      "✓ tokenised: 1C22THS_00001272.json\n",
      "✓ tokenised: 1C22THS_00001506.json\n",
      "✓ tokenised: 1C22THS_00001643.json\n",
      "✓ tokenised: 1C22THS_00001977.json\n",
      "✓ tokenised: 1C22THS_00002027.json\n",
      "✓ tokenised: 1C22THS_00002067.json\n",
      "✓ tokenised: 1C22THS_00002197.json\n",
      "✓ tokenised: 1C22THS_00002287.json\n",
      "✓ tokenised: 1C22THS_00002328.json\n",
      "✓ tokenised: 1C22THS_00002367.json\n",
      "✓ tokenised: 1C22THS_00002478.json\n",
      "✓ tokenised: 1C22THS_00002526.json\n",
      "✓ tokenised: 1C22TLT_00000613.json\n",
      "✓ tokenised: 1C22TMS_00100367.json\n",
      "✓ tokenised: 1C22TMS_00100369.json\n",
      "✓ tokenised: 1C22TYY_00000039.json\n",
      "✓ tokenised: 1C22TYY_00000040.json\n",
      "✓ tokenised: 1C23THS_00000006.json\n",
      "✓ tokenised: 1C23THS_00000028.json\n",
      "✓ tokenised: 1C23THS_00000046.json\n",
      "✓ tokenised: 1C23THS_00000166.json\n",
      "✓ tokenised: 1C23THS_00000229.json\n",
      "✓ tokenised: 1C23THS_00000320.json\n",
      "✓ tokenised: 1C24TKN_213.json\n",
      "✓ tokenised: 1C24TKN_236.json\n",
      "✓ tokenised: 1C24TKN_252.json\n",
      "✓ tokenised: 1C24TPG_00006336.json\n",
      "✓ tokenised: 1C24TPG_00006388.json\n",
      "✓ tokenised: 1C24TPG_00006430.json\n",
      "✓ tokenised: 1C24TPG_00007121.json\n",
      "✓ tokenised: 1C24TPG_00007141.json\n",
      "✓ tokenised: 1C24TPG_00007162.json\n",
      "✓ tokenised: 1C24TPG_00007185.json\n",
      "✓ tokenised: 1C24TPG_00007504.json\n",
      "✓ tokenised: 1C24TPG_00007516.json\n",
      "✓ tokenised: 1C24TPG_00007525.json\n",
      "✓ tokenised: 1C24TPG_00007550.json\n",
      "✓ tokenised: 1C24TPG_00007566.json\n",
      "✓ tokenised: 1C24TPG_00007597.json\n",
      "✓ tokenised: 1C24TPG_00007767.json\n",
      "✓ tokenised: 1C24TPG_00007785.json\n",
      "✓ tokenised: 1C24TPG_00007808.json\n",
      "✓ tokenised: 1C24TPG_00007836.json\n",
      "✓ tokenised: 1C24TPG_00007859.json\n",
      "✓ tokenised: 1C24TPG_00008030.json\n",
      "✓ tokenised: 1C24TPG_00008053.json\n",
      "✓ tokenised: 1C24TPG_00008075.json\n",
      "✓ tokenised: 1C24TPG_00008090.json\n",
      "✓ tokenised: 1C24TYY_00000059.json\n",
      "✓ tokenised: 1K24TCT_0002938.json\n",
      "✓ tokenised: 1K24TCT_0002951.json\n",
      "Done.  Files written to /mnt/c/Users/Legion/Documents/jimmy tran/Automated-invoice-processing-system/BIO-TAGGING-RETAG/qhuy_data\n"
     ]
    }
   ],
   "source": [
    "# ── cell / file: split_tokens_and_fix_labels.py ────────────────────────────\n",
    "from pathlib import Path\n",
    "import json, re\n",
    "\n",
    "# ─────────────────── CONFIG ────────────────────────────────────────────────\n",
    "SRC_DIR = Path(r\"/mnt/c/Users/Legion/Documents/jimmy tran/Automated-invoice-processing-system/BIO-TAGGING-RESIZE/qhuy_data\")     # <── output of script #1\n",
    "DST_DIR = Path(r\"/mnt/c/Users/Legion/Documents/jimmy tran/Automated-invoice-processing-system/BIO-TAGGING-RETAG/qhuy_data\")           # <── will be created\n",
    "HEADER_PATTERNS = [\n",
    "    r\"^Đơn vị bán hàng:?$\",\n",
    "    r\"^Mã số thuế:?$\",\n",
    "    r\"^Ký hiệu:?$\",\n",
    "    r\"^Số:?$\",\n",
    "    r\"^Tên đơn vị:?$\",\n",
    "    r\"^Hình thức thanh toán:?$\",\n",
    "    r\"^Cộng tiền hàng:?$\",\n",
    "    r\"^Tiền thuế GTGT:?$\",\n",
    "    r\"^Tổng tiền thanh toán:?$\",\n",
    "]\n",
    "HEADER_RE = re.compile(\"|\".join(HEADER_PATTERNS), re.IGNORECASE)\n",
    "\n",
    "DST_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def split_token(word):\n",
    "    # simple whitespace split; keeps punctuation with the token it belongs to\n",
    "    return word.split()\n",
    "\n",
    "def propagate_label(label, n):\n",
    "    if label == \"O\" or n == 1:\n",
    "        return [label] * n\n",
    "    tag = label.split(\"-\", 1)[-1]\n",
    "    return [\"B-\" + tag] + [\"I-\" + tag] * (n - 1)\n",
    "\n",
    "for p in SRC_DIR.glob(\"*.json\"):\n",
    "    data = json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "    new_words, new_bboxes, new_labels = [], [], []\n",
    "\n",
    "    for word, bbox, label in zip(data[\"words\"], data[\"bboxes\"], data[\"labels\"]):\n",
    "        # 1) If header phrase → label = \"O\"\n",
    "        if HEADER_RE.match(word):\n",
    "            pieces = split_token(word)\n",
    "            new_words.extend(pieces)\n",
    "            new_bboxes.extend([bbox] * len(pieces))\n",
    "            new_labels.extend([\"O\"] * len(pieces))\n",
    "            continue\n",
    "\n",
    "        # 2) Normal entity token: split + propagate BIO\n",
    "        pieces = split_token(word)\n",
    "        new_words.extend(pieces)\n",
    "        new_bboxes.extend([bbox] * len(pieces))\n",
    "        new_labels.extend(propagate_label(label, len(pieces)))\n",
    "\n",
    "    # 3) Write updated record\n",
    "    data[\"words\"]  = new_words\n",
    "    data[\"bboxes\"] = new_bboxes\n",
    "    data[\"labels\"] = new_labels\n",
    "\n",
    "    out = DST_DIR / p.name\n",
    "    out.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    print(\"✓ tokenised:\", p.name)\n",
    "\n",
    "print(f\"Done.  Files written to {DST_DIR}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
