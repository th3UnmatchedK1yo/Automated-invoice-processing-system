{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a2f489c",
   "metadata": {},
   "source": [
    "## import thu vien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "30c3d207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from transformers import (\n",
    "    LayoutLMv3Processor,\n",
    "    LayoutLMv3ForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5a1ead",
   "metadata": {},
   "source": [
    "## cau hinh path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ea368318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üí° ƒê·ªïi path ph√π h·ª£p v·ªõi m√°y b·∫°n\n",
    "JSONL_PATH = \"/mnt/c/Users/Legion/Documents/jimmy tran/Automated-invoice-processing-system/LayoutLMV3/outputJSONL/layoutLMV3.jsonl\"\n",
    "LABEL_FOLDER = \"/mnt/c/Users/Legion/Documents/jimmy tran/Automated-invoice-processing-system/pipeline_LayoutLMV3/label2id_Folder\"\n",
    "IMAGE_FOLDER = \"/mnt/c/Users/Legion/Documents/jimmy tran/Automated-invoice-processing-system/converted_pngs\"\n",
    "OUTPUT_DIR = \"/mnt/c/Users/Legion/Documents/jimmy tran/Automated-invoice-processing-system/Finetuned_Model/LayoutLMV3_model\"\n",
    "MODEL_NAME = \"microsoft/layoutlmv3-base\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c51737",
   "metadata": {},
   "source": [
    "## LOAD processor + label maps ===\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "74b5fc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMv3ForTokenClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# === Load model ===\n",
    "model = LayoutLMv3ForTokenClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(label2id),\n",
    "    label2id=label2id,\n",
    "    id2label=id2label\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3b9b815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load label maps ===\n",
    "label2id = json.load(open(os.path.join(LABEL_FOLDER, \"label2id.json\"), encoding=\"utf-8\"))\n",
    "id2label = {int(k): v for k, v in json.load(open(os.path.join(LABEL_FOLDER, \"id2label.json\"), encoding=\"utf-8\")).items()}\n",
    "\n",
    "# === Load processor ===\n",
    "processor = LayoutLMv3Processor.from_pretrained(MODEL_NAME, apply_ocr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "221afd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã S·ªë nh√£n ƒë∆∞·ª£c model h·ªó tr·ª£ (num_labels): 20\n",
      "üîé Gi√° tr·ªã label_id cao nh·∫•t: 19\n"
     ]
    }
   ],
   "source": [
    "print(f\"üìã S·ªë nh√£n ƒë∆∞·ª£c model h·ªó tr·ª£ (num_labels): {len(label2id)}\")\n",
    "print(f\"üîé Gi√° tr·ªã label_id cao nh·∫•t: {max(label2id.values())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40877f6",
   "metadata": {},
   "source": [
    "## dinh nghia dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a1ca147c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Dataset class ===\n",
    "class InvoiceDataset(Dataset):\n",
    "    def __init__(self, jsonl_path, label2id, processor, image_folder):\n",
    "        self.processor = processor\n",
    "        self.label2id = label2id\n",
    "        self.image_folder = image_folder\n",
    "\n",
    "        with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            self.samples = []\n",
    "            for i, line in enumerate(f):\n",
    "                if line.strip():\n",
    "                    data = json.loads(line.strip())\n",
    "                    if not all(k in data for k in [\"words\", \"bboxes\", \"labels\", \"image_path\"]):\n",
    "                        print(f\"‚ö†Ô∏è Sample {i} thi·∫øu key ‚Äî b·ªè qua.\")\n",
    "                        continue\n",
    "                    if not (len(data[\"words\"]) == len(data[\"bboxes\"]) == len(data[\"labels\"])):\n",
    "                        print(f\"‚ö†Ô∏è Sample {i} ƒë·ªô d√†i kh√¥ng kh·ªõp ‚Äî b·ªè qua.\")\n",
    "                        continue\n",
    "                    self.samples.append(data)\n",
    "\n",
    "        print(f\"üìÑ Loaded {len(self.samples)} h√≥a ƒë∆°n h·ª£p l·ªá t·ª´ {jsonl_path}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.samples[idx]\n",
    "        image_path = os.path.join(self.image_folder, os.path.basename(item[\"image_path\"]))\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        # Chuy·ªÉn nh√£n v√† ki·ªÉm tra k·ªπ\n",
    "        word_labels = []\n",
    "        for i, lbl in enumerate(item[\"labels\"]):\n",
    "            if lbl not in self.label2id:\n",
    "                raise ValueError(f\"‚ùå Nh√£n kh√¥ng h·ª£p l·ªá: '{lbl}' t·∫°i v·ªã tr√≠ {i}\")\n",
    "            label_id = self.label2id[lbl]\n",
    "            if not (0 <= label_id < len(self.label2id)):\n",
    "                raise ValueError(f\"‚ùå label_id {label_id} v∆∞·ª£t gi·ªõi h·∫°n t·∫°i v·ªã tr√≠ {i}\")\n",
    "            word_labels.append(label_id)\n",
    "\n",
    "        encoding = self.processor(\n",
    "            images=image,\n",
    "            text=item[\"words\"],\n",
    "            boxes=item[\"bboxes\"],\n",
    "            word_labels=word_labels,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {k: v.squeeze(0) for k, v in encoding.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3a04d881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå L·ªói ·ªü sample 0: list index out of range\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dataset)):\n",
    "    try:\n",
    "        _ = dataset[i]\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói ·ªü sample {i}: {e}\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4f71cef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ T·∫•t c·∫£ nh√£n ƒë·ªÅu h·ª£p l·ªá trong label2id.\n"
     ]
    }
   ],
   "source": [
    "# Ki·ªÉm tra xem t·∫•t c·∫£ c√°c nh√£n trong file JSONL c√≥ h·ª£p l·ªá kh√¥ng\n",
    "with open(JSONL_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    invalid_labels = set()\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        for lbl in data.get(\"labels\", []):\n",
    "            if lbl not in label2id:\n",
    "                invalid_labels.add(lbl)\n",
    "\n",
    "if invalid_labels:\n",
    "    print(f\"‚ùå C√°c nh√£n KH√îNG t·ªìn t·∫°i trong label2id: {invalid_labels}\")\n",
    "else:\n",
    "    print(\"‚úÖ T·∫•t c·∫£ nh√£n ƒë·ªÅu h·ª£p l·ªá trong label2id.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "87521b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Loaded 25 h√≥a ƒë∆°n h·ª£p l·ªá t·ª´ /mnt/c/Users/Legion/Documents/jimmy tran/Automated-invoice-processing-system/LayoutLMV3/outputJSONL/layoutLMV3.jsonl\n"
     ]
    }
   ],
   "source": [
    "# === T·∫°o dataset ===\n",
    "dataset = InvoiceDataset(JSONL_PATH, label2id, processor, IMAGE_FOLDER)\n",
    "train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=0.1, random_state=42)\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_idx)\n",
    "val_dataset = torch.utils.data.Subset(dataset, val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "857c4534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMv3ForTokenClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# === Load model ===\n",
    "model = LayoutLMv3ForTokenClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(label2id),\n",
    "    label2id=label2id,\n",
    "    id2label=id2label\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "209466bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Evaluation metrics ===\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    preds = predictions.argmax(-1)\n",
    "    true_preds, true_labels = [], []\n",
    "\n",
    "    for pred, label in zip(preds, labels):\n",
    "        for p_i, l_i in zip(pred, label):\n",
    "            if l_i != -100:\n",
    "                true_preds.append(p_i)\n",
    "                true_labels.append(l_i)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        true_labels, true_preds, average=\"macro\", zero_division=0\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9a920b",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "03c209dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2341/1598495159.py:27: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[127]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     18\u001b[39m data_collator = DataCollatorForTokenClassification(\n\u001b[32m     19\u001b[39m     tokenizer=processor.tokenizer,\n\u001b[32m     20\u001b[39m     padding=\u001b[33m\"\u001b[39m\u001b[33mmax_length\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     21\u001b[39m     max_length=\u001b[32m512\u001b[39m,\n\u001b[32m     22\u001b[39m     return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     23\u001b[39m )\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# === Trainer ===\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m trainer = \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompute_metrics\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# === Train and save ===\u001b[39;00m\n\u001b[32m     38\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mCUDA_LAUNCH_BLOCKING\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Legion/Documents/jimmy tran/Automated-invoice-processing-system/erp/lib/python3.12/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Legion/Documents/jimmy tran/Automated-invoice-processing-system/erp/lib/python3.12/site-packages/transformers/trainer.py:457\u001b[39m, in \u001b[36mTrainer.__init__\u001b[39m\u001b[34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics)\u001b[39m\n\u001b[32m    455\u001b[39m \u001b[38;5;28mself\u001b[39m.compute_loss_func = compute_loss_func\n\u001b[32m    456\u001b[39m \u001b[38;5;66;03m# Seed must be set before instantiating the model when using model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m457\u001b[39m enable_full_determinism(\u001b[38;5;28mself\u001b[39m.args.seed) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.full_determinism \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mset_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[38;5;28mself\u001b[39m.hp_name = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    460\u001b[39m \u001b[38;5;28mself\u001b[39m.deepspeed = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Legion/Documents/jimmy tran/Automated-invoice-processing-system/erp/lib/python3.12/site-packages/transformers/trainer_utils.py:105\u001b[39m, in \u001b[36mset_seed\u001b[39m\u001b[34m(seed, deterministic)\u001b[39m\n\u001b[32m    103\u001b[39m np.random.seed(seed)\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m     torch.cuda.manual_seed_all(seed)\n\u001b[32m    107\u001b[39m     \u001b[38;5;66;03m# ^^ safe to call this function even if cuda is not available\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Legion/Documents/jimmy tran/Automated-invoice-processing-system/erp/lib/python3.12/site-packages/torch/_compile.py:51\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     48\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive)\n\u001b[32m     49\u001b[39m     fn.__dynamo_disable = disable_fn  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Legion/Documents/jimmy tran/Automated-invoice-processing-system/erp/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:838\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    836\u001b[39m _maybe_set_eval_frame(_callback_from_stance(\u001b[38;5;28mself\u001b[39m.callback))\n\u001b[32m    837\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m838\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    840\u001b[39m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Legion/Documents/jimmy tran/Automated-invoice-processing-system/erp/lib/python3.12/site-packages/torch/random.py:46\u001b[39m, in \u001b[36mmanual_seed\u001b[39m\u001b[34m(seed)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcuda\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.cuda._is_in_bad_fork():\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmanual_seed_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmps\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.mps._is_in_bad_fork():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Legion/Documents/jimmy tran/Automated-invoice-processing-system/erp/lib/python3.12/site-packages/torch/cuda/random.py:128\u001b[39m, in \u001b[36mmanual_seed_all\u001b[39m\u001b[34m(seed)\u001b[39m\n\u001b[32m    125\u001b[39m         default_generator = torch.cuda.default_generators[i]\n\u001b[32m    126\u001b[39m         default_generator.manual_seed(seed)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m \u001b[43m_lazy_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_all\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Legion/Documents/jimmy tran/Automated-invoice-processing-system/erp/lib/python3.12/site-packages/torch/cuda/__init__.py:302\u001b[39m, in \u001b[36m_lazy_call\u001b[39m\u001b[34m(callable, **kwargs)\u001b[39m\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _initialization_lock:\n\u001b[32m    301\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[32m--> \u001b[39m\u001b[32m302\u001b[39m         \u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    304\u001b[39m         \u001b[38;5;66;03m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[39;00m\n\u001b[32m    305\u001b[39m         \u001b[38;5;66;03m# file system to get traceback info. Patch linecache or do something\u001b[39;00m\n\u001b[32m    306\u001b[39m         \u001b[38;5;66;03m# else here if this ends up being important.\u001b[39;00m\n\u001b[32m    307\u001b[39m         \u001b[38;5;28;01mglobal\u001b[39;00m _lazy_seed_tracker\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/Legion/Documents/jimmy tran/Automated-invoice-processing-system/erp/lib/python3.12/site-packages/torch/cuda/random.py:126\u001b[39m, in \u001b[36mmanual_seed_all.<locals>.cb\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(device_count()):\n\u001b[32m    125\u001b[39m     default_generator = torch.cuda.default_generators[i]\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m     \u001b[43mdefault_generator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Training args ===\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=5,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    remove_unused_columns=False,\n",
    "    fp16=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "# === Data collator ===\n",
    "data_collator = DataCollatorForTokenClassification(\n",
    "    tokenizer=processor.tokenizer,\n",
    "    padding=\"max_length\",\n",
    "    max_length=512,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# === Trainer ===\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# === Train and save ===\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model()\n",
    "processor.tokenizer.save_pretrained(OUTPUT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
